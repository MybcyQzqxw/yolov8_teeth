#!/usr/bin/env python3
"""
YOLOv8ç‰™é½¿æ£€æµ‹æ¼”ç¤ºå·¥å…·ç±»
æä¾›å•å›¾æ£€æµ‹ã€å¯è§†åŒ–å¯¹æ¯”ã€IoUåˆ†æç­‰åŠŸèƒ½
"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from matplotlib import rcParams
from ultralytics import YOLO
import yaml
from pathlib import Path
from typing import List, Dict, Tuple, Optional


def find_data_yaml(image_path: str) -> str:
    """
    æ ¹æ®å›¾ç‰‡è·¯å¾„è‡ªåŠ¨æŸ¥æ‰¾å¯¹åº”çš„data.yamlæ–‡ä»¶
    
    Args:
        image_path: å›¾ç‰‡æ–‡ä»¶è·¯å¾„
        
    Returns:
        data.yamlæ–‡ä»¶è·¯å¾„
    """
    from pathlib import Path
    
    image_path = Path(image_path)
    
    # å‘ä¸ŠæŸ¥æ‰¾åŒ…å«data.yamlçš„ç›®å½•
    for parent in image_path.parents:
        data_yaml_path = parent / "data.yaml"
        if data_yaml_path.exists():
            return str(data_yaml_path)
    
    raise FileNotFoundError(f"æœªæ‰¾åˆ°data.yamlæ–‡ä»¶ï¼Œè¯·æ£€æŸ¥å›¾ç‰‡è·¯å¾„: {image_path}")


class DentalDetectionDemo:
    """ç‰™é½¿æ£€æµ‹æ¼”ç¤ºç±»"""
    
    def __init__(self, model_path: str, data_yaml: Optional[str] = None):
        """
        åˆå§‹åŒ–æ¼”ç¤ºç±»
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
            data_yaml: æ•°æ®é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œä»…åœ¨éœ€è¦ç±»åˆ«ä¿¡æ¯æˆ–æ ‡ç­¾å¯¹æ¯”æ—¶ä½¿ç”¨ï¼‰
        """
        self.model_path = model_path
        self.data_yaml = data_yaml
        self.model = None
        self.class_names = []
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“å’Œé¢œè‰²
        rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
        rcParams['axes.unicode_minus'] = False
        
        self.GT_COLOR = 'lime'
        self.PRED_COLOR = 'red'
        self.GT_TEXT_COLOR = 'darkgreen' 
        self.PRED_TEXT_COLOR = 'darkred'
        
        self._load_model_and_config()
    
    def _load_model_and_config(self):
        """åŠ è½½æ¨¡å‹å’Œé…ç½®"""
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å­˜åœ¨æ€§
        if not os.path.exists(self.model_path):
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
        
        # åŠ è½½æ¨¡å‹
        print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
        self.model = YOLO(self.model_path)
        print("æ¨¡å‹åŠ è½½æˆåŠŸ!")
        
        # å¦‚æœæä¾›äº†æ•°æ®é…ç½®æ–‡ä»¶ï¼Œåˆ™è¯»å–ç±»åˆ«åç§°
        if self.data_yaml:
            if not os.path.exists(self.data_yaml):
                raise FileNotFoundError(f"æ•°æ®é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.data_yaml}")
            
            with open(self.data_yaml, 'r', encoding='utf-8') as f:
                data_config = yaml.safe_load(f)
                self.class_names = data_config.get('names', ['Class_0', 'Class_1', 'Class_2', 'Class_3'])
            
            print(f"ç±»åˆ«åç§°: {self.class_names}")
        else:
            # å¦‚æœæ²¡æœ‰æä¾›é…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤ç±»åˆ«åç§°
            self.class_names = ['Class_0', 'Class_1', 'Class_2', 'Class_3']
            print("æœªæä¾›æ•°æ®é…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤ç±»åˆ«åç§°")
    
    def get_available_images(self, test_dir: str, max_count: int = 20) -> List[Path]:
        """
        è·å–æµ‹è¯•å›¾ç‰‡åˆ—è¡¨
        
        Args:
            test_dir: æµ‹è¯•å›¾ç‰‡ç›®å½•
            max_count: æœ€å¤§è¿”å›æ•°é‡
            
        Returns:
            å›¾ç‰‡è·¯å¾„åˆ—è¡¨
        """
        if not os.path.exists(test_dir):
            raise FileNotFoundError(f"æµ‹è¯•å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {test_dir}")
        
        images = []
        for ext in ['.jpg', '.jpeg', '.png', '.bmp']:
            images.extend(Path(test_dir).glob(f'*{ext}'))
            images.extend(Path(test_dir).glob(f'*{ext.upper()}'))
        
        return sorted(images)[:max_count]
    
    def load_ground_truth_labels(self, label_path: str) -> List[List[float]]:
        """
        åŠ è½½çœŸå®æ ‡ç­¾
        
        Args:
            label_path: æ ‡ç­¾æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ ‡ç­¾åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º[class_id, x_center, y_center, width, height]
        """
        labels = []
        if os.path.exists(label_path):
            with open(label_path, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) >= 5:
                        labels.append([float(x) for x in parts])
        return labels
    
    def denormalize_bbox(self, bbox: List[float], img_width: int, img_height: int) -> Tuple[int, int, int, int]:
        """
        å°†YOLOæ ¼å¼çš„å½’ä¸€åŒ–è¾¹ç•Œæ¡†è½¬æ¢ä¸ºåƒç´ åæ ‡
        
        Args:
            bbox: [x_center, y_center, width, height] (å½’ä¸€åŒ–)
            img_width: å›¾åƒå®½åº¦
            img_height: å›¾åƒé«˜åº¦
            
        Returns:
            (x_min, y_min, x_max, y_max) åƒç´ åæ ‡
        """
        x_center, y_center, width, height = bbox
        x_center *= img_width
        y_center *= img_height
        width *= img_width
        height *= img_height
        
        x_min = x_center - width / 2
        y_min = y_center - height / 2
        x_max = x_center + width / 2
        y_max = y_center + height / 2
        
        return int(x_min), int(y_min), int(x_max), int(y_max)
    
    def predict_image(self, image_path: str, conf_threshold: float = 0.1) -> List[Dict]:
        """
        å¯¹å›¾åƒè¿›è¡Œé¢„æµ‹
        
        Args:
            image_path: å›¾åƒè·¯å¾„
            conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            
        Returns:
            é¢„æµ‹ç»“æœåˆ—è¡¨
        """
        results = self.model.predict(image_path, verbose=False)
        predictions = []
        
        if results and len(results) > 0 and results[0].boxes is not None:
            boxes = results[0].boxes
            for box in boxes:
                x_min, y_min, x_max, y_max = box.xyxy[0].cpu().numpy()
                confidence = box.conf[0].cpu().numpy()
                class_id = int(box.cls[0].cpu().numpy())
                
                if confidence >= conf_threshold:
                    predictions.append({
                        'bbox': [x_min, y_min, x_max, y_max],
                        'confidence': confidence,
                        'class_id': class_id,
                        'class_name': self.class_names[class_id] if class_id < len(self.class_names) else f'Class{class_id}'
                    })
        
        return predictions
    
    def calculate_iou(self, box1: List[float], box2: List[float]) -> float:
        """è®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„IoU"""
        x1_min, y1_min, x1_max, y1_max = box1
        x2_min, y2_min, x2_max, y2_max = box2
        
        # è®¡ç®—äº¤é›†
        inter_x_min = max(x1_min, x2_min)
        inter_y_min = max(y1_min, y2_min)
        inter_x_max = min(x1_max, x2_max)
        inter_y_max = min(y1_max, y2_max)
        
        if inter_x_min >= inter_x_max or inter_y_min >= inter_y_max:
            return 0.0
        
        inter_area = (inter_x_max - inter_x_min) * (inter_y_max - inter_y_min)
        box1_area = (x1_max - x1_min) * (y1_max - y1_min)
        box2_area = (x2_max - x2_min) * (y2_max - y2_min)
        union_area = box1_area + box2_area - inter_area
        
        return inter_area / union_area if union_area > 0 else 0.0
    
    def match_predictions_with_ground_truth(self, gt_labels: List[List[float]], predictions: List[Dict], 
                                          image_shape: tuple, iou_threshold: float = 0.5) -> Dict:
        """
        åŒ¹é…é¢„æµ‹ç»“æœä¸çœŸå®æ ‡ç­¾
        
        Args:
            gt_labels: çœŸå®æ ‡ç­¾åˆ—è¡¨ (YOLOæ ¼å¼)
            predictions: é¢„æµ‹ç»“æœåˆ—è¡¨
            image_shape: å›¾åƒå½¢çŠ¶ (height, width)
            iou_threshold: IoUé˜ˆå€¼
            
        Returns:
            åŒ¹é…åˆ†æç»“æœ
        """
        img_height, img_width = image_shape
        
        # è½¬æ¢çœŸå®æ ‡ç­¾ä¸ºåƒç´ åæ ‡
        gt_boxes = []
        for label in gt_labels:
            class_id, x_center, y_center, width, height = label
            x_min, y_min, x_max, y_max = self.denormalize_bbox([x_center, y_center, width, height], img_width, img_height)
            gt_boxes.append([x_min, y_min, x_max, y_max])
        
        matched_gt = set()
        matched_pred = set()
        matches = []
        
        # ä¸ºæ¯ä¸ªçœŸå®æ ‡ç­¾æ‰¾æœ€ä½³åŒ¹é…çš„é¢„æµ‹
        for i, gt_box in enumerate(gt_boxes):
            best_iou = 0
            best_pred_idx = -1
            
            for j, pred in enumerate(predictions):
                if j in matched_pred:
                    continue
                    
                pred_box = pred['bbox']
                iou = self.calculate_iou(gt_box, pred_box)
                
                if iou > best_iou:
                    best_iou = iou
                    best_pred_idx = j
            
            if best_iou > iou_threshold:
                matched_gt.add(i)
                matched_pred.add(best_pred_idx)
                gt_class = self.class_names[int(gt_labels[i][0])]
                pred_class = predictions[best_pred_idx]['class_name']
                conf = predictions[best_pred_idx]['confidence']
                
                matches.append({
                    'gt_idx': i,
                    'pred_idx': best_pred_idx,
                    'gt_class': gt_class,
                    'pred_class': pred_class,
                    'confidence': conf,
                    'iou': best_iou
                })
        
        return {
            'matches': matches,
            'matched_gt_count': len(matched_gt),
            'matched_pred_count': len(matched_pred),
            'total_gt': len(gt_labels),
            'total_pred': len(predictions),
            'false_negatives': len(gt_labels) - len(matched_gt),
            'false_positives': len(predictions) - len(matched_pred)
        }
    
    def analyze_detection_results(self, gt_labels: List[List[float]], predictions: List[Dict], 
                                img_width: int, img_height: int, iou_threshold: float = 0.5) -> Dict:
        """
        åˆ†ææ£€æµ‹ç»“æœ
        
        Args:
            gt_labels: çœŸå®æ ‡ç­¾
            predictions: é¢„æµ‹ç»“æœ
            img_width: å›¾åƒå®½åº¦
            img_height: å›¾åƒé«˜åº¦
            iou_threshold: IoUé˜ˆå€¼
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        # è½¬æ¢çœŸå®æ ‡ç­¾ä¸ºåƒç´ åæ ‡
        gt_boxes = []
        for label in gt_labels:
            class_id, x_center, y_center, width, height = label
            x_min, y_min, x_max, y_max = self.denormalize_bbox(
                [x_center, y_center, width, height], img_width, img_height
            )
            gt_boxes.append((x_min, y_min, x_max, y_max))
        
        matched_gt = set()
        matched_pred = set()
        matches = []
        
        for i, gt_box in enumerate(gt_boxes):
            best_iou = 0
            best_pred_idx = -1
            
            for j, pred in enumerate(predictions):
                pred_box = pred['bbox']
                iou = self.calculate_iou(gt_box, pred_box)
                
                if iou > best_iou:
                    best_iou = iou
                    best_pred_idx = j
            
            if best_iou > iou_threshold:
                matched_gt.add(i)
                matched_pred.add(best_pred_idx)
                gt_class = self.class_names[int(gt_labels[i][0])]
                pred_class = predictions[best_pred_idx]['class_name']
                conf = predictions[best_pred_idx]['confidence']
                
                matches.append({
                    'gt_idx': i,
                    'pred_idx': best_pred_idx,
                    'gt_class': gt_class,
                    'pred_class': pred_class,
                    'confidence': conf,
                    'iou': best_iou
                })
        
        return {
            'matches': matches,
            'matched_gt_count': len(matched_gt),
            'matched_pred_count': len(matched_pred),
            'total_gt': len(gt_labels),
            'total_pred': len(predictions),
            'false_negatives': len(gt_labels) - len(matched_gt),
            'false_positives': len(predictions) - len(matched_pred)
        }
    
    def visualize_detection(self, image_path: str, save_path: Optional[str] = None, show_ground_truth: bool = True) -> Dict:
        """
        å®Œæ•´çš„æ£€æµ‹å¯è§†åŒ–æµç¨‹
        
        Args:
            image_path: å›¾åƒè·¯å¾„
            save_path: ä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            show_ground_truth: æ˜¯å¦æ˜¾ç¤ºçœŸå®æ ‡ç­¾ï¼ˆéœ€è¦data_yamlï¼‰
            
        Returns:
            æ£€æµ‹åˆ†æç»“æœ
        """
        # è¯»å–å›¾åƒ
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
        
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        img_height, img_width = image.shape[:2]
        
        # è·å–é¢„æµ‹ç»“æœ
        predictions = self.predict_image(image_path)
        
        result = {
            'image_shape': (img_height, img_width),
            'predictions': predictions,
            'ground_truth': [],
            'analysis': {}
        }
        
        # å¦‚æœéœ€è¦æ˜¾ç¤ºçœŸå®æ ‡ç­¾ä¸”æä¾›äº†é…ç½®æ–‡ä»¶
        if show_ground_truth and self.data_yaml:
            # åŠ è½½çœŸå®æ ‡ç­¾
            image_name = os.path.splitext(os.path.basename(image_path))[0]
            label_dir = os.path.dirname(image_path).replace('images', 'labels')
            label_path = os.path.join(label_dir, f"{image_name}.txt")
            
            gt_labels = []
            if os.path.exists(label_path):
                gt_labels = self.load_ground_truth_labels(label_path)
                result['ground_truth'] = gt_labels
                
                # åŒ¹é…çœŸå®æ ‡ç­¾å’Œé¢„æµ‹ç»“æœ
                analysis = self.match_predictions_with_ground_truth(gt_labels, predictions, image.shape[:2])
                result['analysis'] = analysis
        elif show_ground_truth and not self.data_yaml:
            print("è­¦å‘Š: æœªæä¾›æ•°æ®é…ç½®æ–‡ä»¶ï¼Œæ— æ³•æ˜¾ç¤ºçœŸå®æ ‡ç­¾")
        
        # åˆ›å»ºå¯è§†åŒ–
        plt.figure(figsize=(15, 10))
        plt.imshow(image)
        plt.axis('off')
        
        # ç»˜åˆ¶é¢„æµ‹ç»“æœ
        for pred in predictions:
            x_min, y_min, x_max, y_max = pred['bbox']
            confidence = pred['confidence']
            class_name = pred['class_name']
            
            rect = plt.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min,
                               linewidth=2, edgecolor='red', facecolor='none', alpha=0.8)
            plt.gca().add_patch(rect)
            
            label = f"{class_name}: {confidence:.2f}"
            plt.text(x_min, y_min - 5, label, bbox=dict(boxstyle="round,pad=0.3", facecolor='red', alpha=0.7),
                    fontsize=10, color='white', weight='bold')
        
        # å¦‚æœæœ‰çœŸå®æ ‡ç­¾ï¼Œç»˜åˆ¶å®ƒä»¬
        if show_ground_truth and self.data_yaml and result['ground_truth']:
            for gt in result['ground_truth']:
                class_id, x_center, y_center, width, height = gt
                x_min, y_min, x_max, y_max = self.denormalize_bbox(gt[1:], img_width, img_height)
                class_name = self.class_names[int(class_id)] if int(class_id) < len(self.class_names) else f'Class_{int(class_id)}'
                
                rect = plt.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min,
                                   linewidth=2, edgecolor='green', facecolor='none', alpha=0.8, linestyle='--')
                plt.gca().add_patch(rect)
                
                plt.text(x_max, y_max + 15, f"GT: {class_name}", 
                        bbox=dict(boxstyle="round,pad=0.3", facecolor='green', alpha=0.7),
                        fontsize=10, color='white', weight='bold')
        
        plt.title(f"æ£€æµ‹ç»“æœ: {os.path.basename(image_path)}", fontsize=14, weight='bold')
        
        # æ·»åŠ å›¾ä¾‹
        if show_ground_truth and self.data_yaml and result['ground_truth']:
            legend_elements = [
                plt.Line2D([0], [0], color='red', lw=2, label='é¢„æµ‹ç»“æœ'),
                plt.Line2D([0], [0], color='green', lw=2, linestyle='--', label='çœŸå®æ ‡ç­¾')
            ]
            plt.legend(handles=legend_elements, loc='upper right')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            print(f"ç»“æœä¿å­˜åˆ°: {save_path}")
        
        plt.show()
        
        return result
        gt_labels = self.load_ground_truth_labels(label_path)
        
        # æ¨¡å‹é¢„æµ‹
        predictions = self.predict_image(image_path)
        
        # åˆ†æç»“æœ
        analysis = self.analyze_detection_results(gt_labels, predictions, img_width, img_height)
        
        # å¯è§†åŒ–
        self._plot_comparison(image, gt_labels, predictions, img_width, img_height, analysis)
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“ ç»“æœå·²ä¿å­˜è‡³: {save_path}")
        
        plt.show()
        
        return analysis
    
    def _plot_comparison(self, image: np.ndarray, gt_labels: List[List[float]], 
                        predictions: List[Dict], img_width: int, img_height: int, analysis: Dict):
        """ç»˜åˆ¶å¯¹æ¯”å›¾"""
        fig, axes = plt.subplots(1, 3, figsize=(24, 8))
        
        TEXT_BG = dict(boxstyle="round,pad=0.3", facecolor='white', alpha=0.9, edgecolor='black')
        
        # 1. åŸå§‹å›¾åƒ
        axes[0].imshow(image)
        axes[0].set_title('åŸå§‹å›¾åƒ', fontsize=16, fontweight='bold', pad=20)
        axes[0].axis('off')
        
        # 2. çœŸå®æ ‡ç­¾
        axes[1].imshow(image)
        axes[1].set_title(f'çœŸå®æ ‡ç­¾ ({len(gt_labels)} ä¸ª)', fontsize=16, fontweight='bold', 
                         pad=20, color='darkgreen')
        axes[1].axis('off')
        
        for i, label in enumerate(gt_labels):
            class_id, x_center, y_center, width, height = label
            x_min, y_min, x_max, y_max = self.denormalize_bbox(
                [x_center, y_center, width, height], img_width, img_height
            )
            
            rect = patches.Rectangle(
                (x_min, y_min), x_max - x_min, y_max - y_min,
                linewidth=3, edgecolor=self.GT_COLOR, facecolor='none', alpha=0.8
            )
            axes[1].add_patch(rect)
            
            class_name = self.class_names[int(class_id)] if int(class_id) < len(self.class_names) else f'Class{int(class_id)}'
            axes[1].text(x_min, y_min - 10, f'GT-{i+1}: {class_name}', 
                       fontsize=11, color=self.GT_TEXT_COLOR, fontweight='bold', bbox=TEXT_BG)
        
        # 3. é¢„æµ‹ç»“æœ
        axes[2].imshow(image)
        axes[2].set_title(f'é¢„æµ‹ç»“æœ ({len(predictions)} ä¸ª)', fontsize=16, fontweight='bold',
                         pad=20, color='darkred')
        axes[2].axis('off')
        
        for i, pred in enumerate(predictions):
            x_min, y_min, x_max, y_max = pred['bbox']
            
            rect = patches.Rectangle(
                (x_min, y_min), x_max - x_min, y_max - y_min,
                linewidth=3, edgecolor=self.PRED_COLOR, facecolor='none', alpha=0.8
            )
            axes[2].add_patch(rect)
            
            axes[2].text(x_min, y_min - 10, 
                       f"Pred-{i+1}: {pred['class_name']} ({pred['confidence']:.2f})", 
                       fontsize=11, color=self.PRED_TEXT_COLOR, fontweight='bold', bbox=TEXT_BG)
        
        plt.tight_layout()
        
        # æ‰“å°åˆ†æç»“æœ
        self._print_analysis(analysis)
    
    def predict_only(self, image_path: str, save_path: Optional[str] = None, conf_threshold: float = 0.3) -> Dict:
        """
        ä»…è¿›è¡Œé¢„æµ‹çš„æ–¹æ³•ï¼Œä¸éœ€è¦çœŸå®æ ‡ç­¾
        
        Args:
            image_path: å›¾åƒè·¯å¾„
            save_path: ä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            
        Returns:
            é¢„æµ‹ç»“æœ
        """
        # è¯»å–å›¾åƒ
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
        
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        img_height, img_width = image.shape[:2]
        
        # è·å–é¢„æµ‹ç»“æœ
        predictions = self.predict_image(image_path, conf_threshold)
        
        result = {
            'image_path': image_path,
            'image_shape': (img_height, img_width),
            'predictions': predictions,
            'prediction_count': len(predictions)
        }
        
        # åˆ›å»ºå¯è§†åŒ–
        plt.figure(figsize=(12, 8))
        plt.imshow(image)
        plt.axis('off')
        
        # ç»˜åˆ¶é¢„æµ‹ç»“æœ
        for pred in predictions:
            x_min, y_min, x_max, y_max = pred['bbox']
            confidence = pred['confidence']
            class_name = pred['class_name']
            
            rect = plt.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min,
                               linewidth=2, edgecolor='red', facecolor='none', alpha=0.8)
            plt.gca().add_patch(rect)
            
            label = f"{class_name}: {confidence:.2f}"
            plt.text(x_min, y_min - 5, label, bbox=dict(boxstyle="round,pad=0.3", facecolor='red', alpha=0.7),
                    fontsize=10, color='white', weight='bold')
        
        plt.title(f"æ£€æµ‹ç»“æœ: {os.path.basename(image_path)} (å…±æ‰¾åˆ° {len(predictions)} ä¸ªç›®æ ‡)", 
                 fontsize=14, weight='bold')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            print(f"ç»“æœä¿å­˜åˆ°: {save_path}")
        
        plt.show()
        
        return result
    
    def _print_analysis(self, analysis: Dict):
        """æ‰“å°åˆ†æç»“æœ"""
        print("\n" + "="*70)
        print("æ£€æµ‹ç»“æœåˆ†æ:")
        print("="*70)
        print(f"çœŸå®æ ‡ç­¾: {analysis['total_gt']} ä¸ª")
        print(f"é¢„æµ‹ç»“æœ: {analysis['total_pred']} ä¸ª")
        print(f"æˆåŠŸåŒ¹é…: {analysis['matched_gt_count']} ä¸ª")
        print(f"æ¼æ£€ (FN): {analysis['false_negatives']} ä¸ª") 
        print(f"è¯¯æ£€ (FP): {analysis['false_positives']} ä¸ª")
        
        if analysis['matches']:
            print(f"\nåŒ¹é…è¯¦æƒ…:")
            for match in analysis['matches']:
                print(f"   GT-{match['gt_idx']+1} ({match['gt_class']}) <-> "
                      f"Pred-{match['pred_idx']+1} ({match['pred_class']}, "
                      f"{match['confidence']:.2f}) | IoU: {match['iou']:.3f}")
    
    def show_image_selector(self, test_dir: str):
        """æ˜¾ç¤ºå›¾ç‰‡é€‰æ‹©å™¨"""
        images = self.get_available_images(test_dir)
        if not images:
            print(f"é”™è¯¯: åœ¨ {test_dir} ä¸­æœªæ‰¾åˆ°æµ‹è¯•å›¾ç‰‡")
            return []
        
        print(f"å¯é€‰æ‹©çš„æµ‹è¯•å›¾ç‰‡ (å…± {len(images)} å¼ ):")
        for i, img_path in enumerate(images):
            print(f"   {i+1:2d}. {img_path.name}")
        
        return images
